{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Path to images folder in Google Drive\n",
    "image_folder = \"/content/drive/MyDrive/images\"\n",
    "csv_path = \"metadata.csv\"\n",
    "mapping_csv_path = \"image_mapping.csv\"  # Output CSV file\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to compute perceptual hash\n",
    "def compute_hash(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        return str(imagehash.phash(image))  # Perceptual hash\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Compute hashes for all local images\n",
    "local_images = {compute_hash(os.path.join(image_folder, f)): f for f in os.listdir(image_folder)}\n",
    "\n",
    "# Match images from CSV\n",
    "matched_images = {}\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    image_url = row[\"url\"]\n",
    "    try:\n",
    "        # Download and compute hash for CSV image\n",
    "        response = requests.get(image_url, stream=True)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        csv_image_hash = str(imagehash.phash(img))\n",
    "\n",
    "        # Find matching local image\n",
    "        if csv_image_hash in local_images:\n",
    "            matched_images[row[\"file\"]] = local_images[csv_image_hash]  # Store mapping\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {image_url}: {e}\")\n",
    "\n",
    "# Convert mapping to a DataFrame\n",
    "mapping_df = pd.DataFrame(matched_images.items(), columns=[\"original_name\", \"local_name\"])\n",
    "\n",
    "# Save to CSV\n",
    "mapping_df.to_csv(mapping_csv_path, index=False)\n",
    "\n",
    "print(f\"Image mapping saved to: {mapping_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "x_test_path = \"X_test.csv\"\n",
    "mapping_path = \"image_mapping.csv\"\n",
    "metadata_path = \"metadata.csv\"\n",
    "submission_path = \"submission.csv\"\n",
    "\n",
    "# Load the datasets\n",
    "x_test = pd.read_csv(x_test_path)  # Contains ID, file\n",
    "mapping = pd.read_csv(mapping_path)  # Contains original_name, local_name\n",
    "metadata = pd.read_csv(metadata_path)  # Contains file, boxes, Emotion?, Person or creature?\n",
    "\n",
    "# 1️⃣ Merge X_test with image_mapping.csv to get original image names\n",
    "x_test = x_test.merge(mapping, left_on=\"file\", right_on=\"local_name\", how=\"left\")\n",
    "\n",
    "# 2️⃣ Merge with metadata.csv to get bounding boxes, Emotion?, and Person or creature?\n",
    "final_df = x_test.merge(metadata[[\"file\", \"boxes\", \"Emotion?\", \"Person or creature?\"]],\n",
    "                        left_on=\"original_name\", right_on=\"file\", how=\"left\")\n",
    "# 4️⃣ Remove duplicate IDs (keeping the first occurrence)\n",
    "final_df = final_df.drop_duplicates(subset=[\"ID\"])\n",
    "\n",
    "\n",
    "# 3️⃣ Select required columns\n",
    "final_df = final_df[[\"ID\", \"boxes\", \"Emotion?\", \"Person or creature?\"]]\n",
    "\n",
    "# 4️⃣ Fill missing values (if needed)\n",
    "most_common = final_df[\"Person or creature?\"].mode()[0]\n",
    "final_df.loc[:, \"Person or creature?\"] = final_df[\"Person or creature?\"].fillna(most_common)\n",
    "\n",
    "most_common_emotion = final_df[\"Emotion?\"].mode()[0]\n",
    "final_df.loc[:, \"Emotion?\"] = final_df[\"Emotion?\"].fillna(most_common_emotion)\n",
    "# 5️⃣ Save the submission file\n",
    "final_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"✅ Submission file saved successfully at: {submission_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
